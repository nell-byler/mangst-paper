% XXX \todo{Should I mention other differences? a) Different CMD-fitting codes, b) Higher resolution spectra: FWHM$\sim2-3$\ang (SDSS) compared to FWHM$\sim10$\ang (Ruiz-Lara+2018), c) better wavelength coverage: 3000-10,000\ang (SDSS) compared to 4000-5000\ang (Ruiz-Lara+2018), d) Fiber bundle instead of slit, e) true aperture-matched comparison.}

Lifetime SFR: 8.92 +/- 1.4 *10^-3
$z = 0.000547$
%8,486 stars w/ 65,318 ASTs
%77,212 stars in full field; 565,659 ASTs

%------------------------------------------
% the gst catalog explanation
%------------------------------------------
As described in Dalcanton et al. (2009), both new and archival observations were processed uniformly beginning with image reduction via the standard HST pipeline. Using the ANGST data reduction pipeline, we performed photometry on each image with HSTPHOT11 (Dolphin 2000), designed for WFPC2 images, and DOLPHOT,12 running in its ACS-optimized mode, for ACS observations, providing for a uniform treatment of all data. The resultant photometry for each data set was filtered to ensure the final photometric catalogs excluded non-stellar objects such as cosmic rays, hot pixels, and extended sources. For the purposes of this paper, we considered a star well measured if it met the following criteria: a signal-to-noise ratio >4 in both filters, a sharpness value such that (sharp1 + sharp2) 2  0.075, and a crowding parameter such that (crowd1 + crowd2)  0.1. To characterize observational uncertainties, we performed 500,000 artificial star tests on each image. Both the full and filtered (i.e., the “gst” files) photometric catalogs, HST reference images, and CMDs are publicly available on MAST.13 Definitions and detailed descriptions of the filtering criteria and the observational strategies can be found in Dolphin (2000), Dalcanton et al. (2009), and K. Gilbert et al. (2011, in preparation).


%------------------------------------------
% Uncertainties
%------------------------------------------
Uncertainties in SFH measurements can be broken into two sources: random and systematic. Random uncertainties are due to the finite number of stars, and therefore generally scale in amplitude with the sparsity of the observed CMD. In comparison, systematic uncertainties are due to inherent shortcomings with the stellar models (e.g., uncertainties in convective overshooting, mass loss, etc.) used to measure the SFHs, and generally scale as a function of photometric depth, i.e., deeper CMDs provide more secure leverage on the lifetime SFH of a galaxy relative to a shallower CMD because they more age sensitive features and older MSTOs. However, other factors such as the intrinsic SFH and morphologies of key CMD features (e.g., HB, red clump (RC)) can also influence the accuracy. Detailed discussions of computing random and systematic uncertainties for CMD-based SFHs are described in Dolphin (2012, 2013), respectively. Here we provide a brief description of how we computed uncertainties for this sample.
Random uncertainties were computed using a hybrid Monte Carlo process (Duane et al. 1987), with implementation details as described by Dolphin (2013). The result of this Markov Chain Monte Carlo routine is a sample of 104 SFHs whose density is proportional to the probability density, i.e., the density of samples is highest near the maximum likelihood point. Upper and lower random error bars for any given value (e.g., cumulative star formation at a particular point in time) are calculated by identifying the boundaries of the highest-density region containing 68\% of the samples, where the value 68\% adopted is an equivalent percentile range to the ±1σ bounds of a normal distribution.
Systematic uncertainties were computed by running 50 Monte Carlo SFH realizations on the best fit model CMD. For each realization, the model CMD was shifted in log(Teff) and Mbol following the procedure detailed in Dolphin (2012) using the values listed in Table 3, and the SFH was re-measured. From the resulting 50 SFHs, we computed the range that contained 68\% of distributions, and designated this as the systematic uncertainties. As discussed in Dolphin (2012), this technique is designed to produce 1σ uncertainties that include the best fit SFHs as derived with either Padova, BaSTI (Pietrinferni et al. 2004), or Dartmouth stellar evolution models.


%------------------------------------------
% Foreground modelling
%------------------------------------------
We additionally modeled intervening MW foreground stars by adding model foreground stars to the composite synthetic CMD. Specifically, we generated synthetic CMDs using the Dartmouth stellar evolution libraries (Dotter et al. 2008) and the MW structural model presented in de Jong et al. (2010), and allowed MATCH to linearly scale the resulting CMD to model any putative foreground stars that may have contaminated each CMD. The Dartmouth models extend to slightly lower stellar masses (0.1 M⊙) than the Padova models (0.15 M⊙), which allow for a more realistic foreground population model. In general, we found the resulting scaling factors to be quite small, in agreement with the prior expectation that few foreground stars would fall into a typical HST field of view. As previously discussed, in the case of Sagittarius dSph, we used off-galaxy HST/WFPC2 fields as the empirical foreground CMD in the modeling process.

%------------------------------------------
% MC tests
%------------------------------------------
Monte Carlo tests were used to estimate uncertainties due to both random and systematic sources. For each Monte Carlo run, a Poisson random noise generator was used to create a random sampling of the best-fit CMD. This CMD was then processed identically to the original solution, with additive errors in Mbol and log(Teff ) introduced when generating the model CMDs for these solutions. Single shifts in Mbol and log(Teff) are used for each Monte Carlo draw, and the errors themselves were drawn from normal distributions with σ (Mbol ) = 0.41 and σ [log(Teff )] = 0.03. These distributions are designed to mimic the scatter in SFH uncertainties obtained by using alternative isochrone sets to fit the data; we prefer to use this approximation of the model uncertainties rather than directly fitting a variety of isochrone sets because few alternatives exist that fully cover the range of ages, metallicities, and evolutionary states required to adequately model our CMDs. We found that the uncertainties were stable after 50 Monte Carlo tests, and thus conducted 50 realizations for each galaxy. This technique of estimating error on SFHs will be described in greater detail in A. E. Dolphin (2011, in preparation).

%------------------------------------------
% Uncertainties in SFR
%------------------------------------------
In general, uncertainties in the absolute SFHs generally are somewhat anti-correlated between adjacent time bins, such that if the SFR is overestimated in one bin, it is underestimated in the adjacent bin. However, cumulative SFHs, i.e., the stellar mass formed during or previous to each time bin normalized to the integrated final stellar mass, do not share this property, and thus present a more robust way of analyzing SFHs. Uncertainties on the individual cumulative SFHs represent the 16th and 84th percentiles of the distribution of SFHs as determined by Monte Carlo tests.
